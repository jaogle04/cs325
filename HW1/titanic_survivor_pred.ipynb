{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "#### Loading Packages",
   "id": "f6d97ecd2ff6ccc2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T05:54:30.948582Z",
     "start_time": "2025-09-16T05:54:30.944069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt"
   ],
   "id": "39ba64447978dd66",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Functions for Logistic Regression",
   "id": "75ba21c20d7d4b2d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T06:32:46.579288Z",
     "start_time": "2025-09-16T06:32:46.546858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sigmoid (z):\n",
    "#   returns sigmoid = 1/(1 + e^-z)\n",
    "#   -> handles vectors/matrices\n",
    "  sigmoid = 1 / (1 + np.exp(-z))\n",
    "  return sigmoid\n",
    "\n",
    "def initialize_params (m_features, seed=None):\n",
    "#   returns vector (w) of size (m x 1) features with small random numbers, and the scalar b initialized to 0\n",
    "#   -> b = 0\n",
    "#   call this from one-hot encoding or create another section after one-hot encoding to do this\n",
    "#   - plug our samples into this function to get y_hat values\n",
    "  # (0, 0.01) represents a gaussian distribution with mean 0 and std 0.01\n",
    "  # -> might need to be adjusted late for model accuracy\n",
    "  w = np.random.default_rng(seed).normal(0, 0.01, size=(m_features, 1))\n",
    "  b = 0\n",
    "  return w, b\n",
    "\n",
    "def forward (X, w, b):\n",
    "#   returns\n",
    "#     z = X * w + b\n",
    "#     y_hat (pred) = sigmoid(z)\n",
    "  X = X.to_numpy()\n",
    "  z = (X.T * w) + b\n",
    "  y_hat = sigmoid(z)\n",
    "  return y_hat, z\n",
    "\n",
    "def compute_cost (y, y_hat, w, reg_lambda=0.0, eps=1e-12):\n",
    "#   -> computes binary cross-entropy cost w/ optional L2 penalty\n",
    "#   - check with notes:\n",
    "#     -> cost = -1/n * sum(y_i * log(y_hat_i) + (1 - y_i) * log(1 - y_hat_i))\n",
    "#     -> cost += reg_lambda / 2 * sum(w^2)\n",
    "  n = X.shape[0]\n",
    "  cost = (-1 / n) * sum(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat))\n",
    "  return cost\n",
    "\n",
    "def compute_gradients (X, y, y_hat, w, reg_lambda=0.0):\n",
    "#   - dw = (1/n) * X * (y_hat - y) + (reg_lambda / n) * w\n",
    "#   - db = (1/n) * sum(y_hat_i - y_i) -> find the mean difference between y_hat (pred) and y (target)\n",
    "    X = X.to_numpy()\n",
    "    n = X.shape[0] # represents num of features\n",
    "    dw = (1 / n) * X.T  * (y_hat - y) + (reg_lambda / n) * w\n",
    "    db = (1 / n) * (y_hat - y).sum() # .sum() allows us to take a sum of differences between prediction and target\n",
    "    return dw, db\n",
    "\n",
    "def update_params (w, b, dw, db, lr):\n",
    "#   Gradient step -> w: = w - (lr * dw)\n",
    "#                 -> b: = b - (lr * db)\n",
    "  w = w - (lr * dw)\n",
    "  b = b - (lr * db)\n",
    "  return w, b\n",
    "\n",
    "def train (X, y, lr, n_epochs, reg_lambda=0.0, X_val=None, y_val=None):\n",
    "#   I. training loop\n",
    "#       1.) forward pass\n",
    "#       2.) compute cost\n",
    "#       3.) compute gradients\n",
    "#       4.) update parameters\n",
    "#            -> track expected loss for each iteration. if X_val and y_val are provided, it will also track validation loss\n",
    "  features = X.shape[1]\n",
    "  w, b = initialize_params(features, seed=None)\n",
    "  cost_history = []\n",
    "\n",
    "  for epoch in range(n_epochs):\n",
    "    y_hat, z = forward(X, w, b)\n",
    "    cost = compute_cost(y, y_hat, w, reg_lambda, eps=1e-12)\n",
    "    cost_history.append(cost)\n",
    "    dw, db = compute_gradients(X, y, y_hat, w, reg_lambda)\n",
    "    w, b = update_params(w, b, dw, db, lr)\n",
    "\n",
    "#   II. Returns the trained parameters 'w' and 'b' and history of the cost for training and validation sets\n",
    "  return w, b, cost_history\n",
    "\n",
    "def predict_proba (X, w, b):\n",
    "  X = X.to_numpy()\n",
    "  y_hat = X.T * w + b\n",
    "  return y_hat"
   ],
   "id": "bd5e46161ed5a428",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Read in & Clean Data\n",
    "- will need to remove cabin and age columns\n",
    "- some cells in embarked are null so won't need to remove all but can just remove those rows"
   ],
   "id": "b408d3642e6534e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T06:07:36.030442Z",
     "start_time": "2025-09-16T06:07:36.018801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "original_data = pd.read_csv(\"./titanic-data/train.csv\")\n",
    "print(f\"Training data original shape: {original_data.shape}\")\n",
    "\n",
    "# Removing columns and rows will null data cells\n",
    "training_data = original_data.drop(columns = 'Cabin') # removed whole column since majority were NA\n",
    "training_data = training_data.dropna() # cleans out NA values spread out between columns by removing whole entire row\n",
    "\n",
    "# print(f\"Cabin Column Dropped due to many null values:\\n{training_data}\")\n",
    "print(f\"Training data shape after cleaning: {training_data.shape}\")\n",
    "print(f\"Samples Removed: {original_data.shape[0] - training_data.shape[0]}\")"
   ],
   "id": "3654f99c53979659",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data original shape: (891, 12)\n",
      "Training data shape after cleaning: (712, 11)\n",
      "Samples Removed: 179\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### One Hot Encoding",
   "id": "eb87f19b16010b95"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T06:07:37.560017Z",
     "start_time": "2025-09-16T06:07:37.546655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = training_data.drop('Survived', axis = 1)\n",
    "# removes columns that have no effect on an outcome and help reduce dimensionality before training\n",
    "X = X.drop(['PassengerId', 'Name', 'Ticket'], axis = 1)\n",
    "print(f\"Training data before one-hot encoding:\\n\\n{X.head()}\")\n",
    "y = training_data['Survived']\n",
    "\n",
    "X = pd.get_dummies(X, columns=['Sex', 'Embarked'], dtype=int, drop_first = True)\n",
    "\n",
    "# Sex_female and Embarked_C not included due to drop_first being set to True\n",
    "print(\"\\n\\n\")\n",
    "print(f\"Training data after one-hot encoding:\\n\\n{X.head()}\")"
   ],
   "id": "41da79c3f58c6510",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data before one-hot encoding:\n",
      "\n",
      "   Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
      "0       3    male  22.0      1      0   7.2500        S\n",
      "1       1  female  38.0      1      0  71.2833        C\n",
      "2       3  female  26.0      0      0   7.9250        S\n",
      "3       1  female  35.0      1      0  53.1000        S\n",
      "4       3    male  35.0      0      0   8.0500        S\n",
      "\n",
      "\n",
      "\n",
      "Training data after one-hot encoding:\n",
      "\n",
      "   Pclass   Age  SibSp  Parch     Fare  Sex_male  Embarked_Q  Embarked_S\n",
      "0       3  22.0      1      0   7.2500         1           0           1\n",
      "1       1  38.0      1      0  71.2833         0           0           0\n",
      "2       3  26.0      0      0   7.9250         0           0           1\n",
      "3       1  35.0      1      0  53.1000         0           0           1\n",
      "4       3  35.0      0      0   8.0500         1           0           1\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Training Model with Self-Made Functions",
   "id": "cf315745ec930ca1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T06:32:47.828721Z",
     "start_time": "2025-09-16T06:32:47.658280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "learning_rate = 0.05\n",
    "n_epochs = 100\n",
    "valid_params, bias, cost_history = train(X, y, learning_rate, n_epochs, reg_lambda=0.0, X_val=None, y_val=None)\n",
    "print(valid_params)"
   ],
   "id": "7857cdbaf82f6423",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (8) does not match length of index (712)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[33]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m learning_rate = \u001B[32m0.05\u001B[39m\n\u001B[32m      2\u001B[39m n_epochs = \u001B[32m100\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m valid_params, bias, cost_history = \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreg_lambda\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_val\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_val\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[38;5;28mprint\u001B[39m(valid_params)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[32]\u001B[39m\u001B[32m, line 65\u001B[39m, in \u001B[36mtrain\u001B[39m\u001B[34m(X, y, lr, n_epochs, reg_lambda, X_val, y_val)\u001B[39m\n\u001B[32m     63\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_epochs):\n\u001B[32m     64\u001B[39m   y_hat, z = forward(X, w, b)\n\u001B[32m---> \u001B[39m\u001B[32m65\u001B[39m   cost = \u001B[43mcompute_cost\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_hat\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mw\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreg_lambda\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meps\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1e-12\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     66\u001B[39m   cost_history.append(cost)\n\u001B[32m     67\u001B[39m   dw, db = compute_gradients(X, y, y_hat, w, reg_lambda)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[32]\u001B[39m\u001B[32m, line 33\u001B[39m, in \u001B[36mcompute_cost\u001B[39m\u001B[34m(y, y_hat, w, reg_lambda, eps)\u001B[39m\n\u001B[32m     27\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcompute_cost\u001B[39m (y, y_hat, w, reg_lambda=\u001B[32m0.0\u001B[39m, eps=\u001B[32m1e-12\u001B[39m):\n\u001B[32m     28\u001B[39m \u001B[38;5;66;03m#   -> computes binary cross-entropy cost w/ optional L2 penalty\u001B[39;00m\n\u001B[32m     29\u001B[39m \u001B[38;5;66;03m#   - check with notes:\u001B[39;00m\n\u001B[32m     30\u001B[39m \u001B[38;5;66;03m#     -> cost = -1/n * sum(y_i * log(y_hat_i) + (1 - y_i) * log(1 - y_hat_i))\u001B[39;00m\n\u001B[32m     31\u001B[39m \u001B[38;5;66;03m#     -> cost += reg_lambda / 2 * sum(w^2)\u001B[39;00m\n\u001B[32m     32\u001B[39m   n = X.shape[\u001B[32m0\u001B[39m]\n\u001B[32m---> \u001B[39m\u001B[32m33\u001B[39m   cost = (-\u001B[32m1\u001B[39m / n) * \u001B[38;5;28msum\u001B[39m(\u001B[43my\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlog\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_hat\u001B[49m\u001B[43m)\u001B[49m + (\u001B[32m1\u001B[39m - y) * np.log(\u001B[32m1\u001B[39m - y_hat))\n\u001B[32m     34\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m cost\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\cs325-homeworks\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001B[39m, in \u001B[36m_unpack_zerodim_and_defer.<locals>.new_method\u001B[39m\u001B[34m(self, other)\u001B[39m\n\u001B[32m     72\u001B[39m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m\n\u001B[32m     74\u001B[39m other = item_from_zerodim(other)\n\u001B[32m---> \u001B[39m\u001B[32m76\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\cs325-homeworks\\Lib\\site-packages\\pandas\\core\\arraylike.py:202\u001B[39m, in \u001B[36mOpsMixin.__mul__\u001B[39m\u001B[34m(self, other)\u001B[39m\n\u001B[32m    200\u001B[39m \u001B[38;5;129m@unpack_zerodim_and_defer\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m__mul__\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    201\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__mul__\u001B[39m(\u001B[38;5;28mself\u001B[39m, other):\n\u001B[32m--> \u001B[39m\u001B[32m202\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_arith_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moperator\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmul\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\cs325-homeworks\\Lib\\site-packages\\pandas\\core\\series.py:6146\u001B[39m, in \u001B[36mSeries._arith_method\u001B[39m\u001B[34m(self, other, op)\u001B[39m\n\u001B[32m   6144\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_arith_method\u001B[39m(\u001B[38;5;28mself\u001B[39m, other, op):\n\u001B[32m   6145\u001B[39m     \u001B[38;5;28mself\u001B[39m, other = \u001B[38;5;28mself\u001B[39m._align_for_op(other)\n\u001B[32m-> \u001B[39m\u001B[32m6146\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbase\u001B[49m\u001B[43m.\u001B[49m\u001B[43mIndexOpsMixin\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_arith_method\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\cs325-homeworks\\Lib\\site-packages\\pandas\\core\\base.py:1393\u001B[39m, in \u001B[36mIndexOpsMixin._arith_method\u001B[39m\u001B[34m(self, other, op)\u001B[39m\n\u001B[32m   1390\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m np.errstate(\u001B[38;5;28mall\u001B[39m=\u001B[33m\"\u001B[39m\u001B[33mignore\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m   1391\u001B[39m     result = ops.arithmetic_op(lvalues, rvalues, op)\n\u001B[32m-> \u001B[39m\u001B[32m1393\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_construct_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m=\u001B[49m\u001B[43mres_name\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\cs325-homeworks\\Lib\\site-packages\\pandas\\core\\series.py:6242\u001B[39m, in \u001B[36mSeries._construct_result\u001B[39m\u001B[34m(self, result, name)\u001B[39m\n\u001B[32m   6239\u001B[39m \u001B[38;5;66;03m# TODO: result should always be ArrayLike, but this fails for some\u001B[39;00m\n\u001B[32m   6240\u001B[39m \u001B[38;5;66;03m#  JSONArray tests\u001B[39;00m\n\u001B[32m   6241\u001B[39m dtype = \u001B[38;5;28mgetattr\u001B[39m(result, \u001B[33m\"\u001B[39m\u001B[33mdtype\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m-> \u001B[39m\u001B[32m6242\u001B[39m out = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_constructor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m   6243\u001B[39m out = out.__finalize__(\u001B[38;5;28mself\u001B[39m)\n\u001B[32m   6245\u001B[39m \u001B[38;5;66;03m# Set the result's name after __finalize__ is called because __finalize__\u001B[39;00m\n\u001B[32m   6246\u001B[39m \u001B[38;5;66;03m#  would set it back to self.name\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\cs325-homeworks\\Lib\\site-packages\\pandas\\core\\series.py:575\u001B[39m, in \u001B[36mSeries.__init__\u001B[39m\u001B[34m(self, data, index, dtype, name, copy, fastpath)\u001B[39m\n\u001B[32m    573\u001B[39m     index = default_index(\u001B[38;5;28mlen\u001B[39m(data))\n\u001B[32m    574\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m is_list_like(data):\n\u001B[32m--> \u001B[39m\u001B[32m575\u001B[39m     \u001B[43mcom\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrequire_length_match\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    577\u001B[39m \u001B[38;5;66;03m# create/copy the manager\u001B[39;00m\n\u001B[32m    578\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, (SingleBlockManager, SingleArrayManager)):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\cs325-homeworks\\Lib\\site-packages\\pandas\\core\\common.py:573\u001B[39m, in \u001B[36mrequire_length_match\u001B[39m\u001B[34m(data, index)\u001B[39m\n\u001B[32m    569\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    570\u001B[39m \u001B[33;03mCheck the length of data matches the length of the index.\u001B[39;00m\n\u001B[32m    571\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    572\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(data) != \u001B[38;5;28mlen\u001B[39m(index):\n\u001B[32m--> \u001B[39m\u001B[32m573\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    574\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mLength of values \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    575\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m(\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(data)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m) \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    576\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mdoes not match length of index \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    577\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m(\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(index)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m)\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    578\u001B[39m     )\n",
      "\u001B[31mValueError\u001B[39m: Length of values (8) does not match length of index (712)"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Plotting Cost History",
   "id": "8baf407be0f093e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(n_epochs, cost_history, marker='-', linewidth=1.5, label='Train Cost')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Cost')\n",
    "plt.title('Training Cost History')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "41790263138f75ff"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
